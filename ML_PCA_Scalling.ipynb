{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cellular-michigan",
   "metadata": {},
   "source": [
    "## Apply DAiSEE and EmotiW on conventional Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "professional-bridge",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, accuracy_score\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.model_selection import KFold, cross_val_score, cross_validate\n",
    "from sklearn.decomposition import PCA, KernelPCA\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "steady-northwest",
   "metadata": {},
   "outputs": [],
   "source": [
    "# INPUT PATH\n",
    "path = ('C:/Users/hasegawa-lab-pc/OneDrive - Japan Advanced Institute of Science and Technology/Documents/Exp_Shofi/Preprocess and Statistical Analysis/extracted/')\n",
    "\n",
    "# DAISEE\n",
    "with open(path+'daisee_28_186.pkl','rb') as f:\n",
    "    X_train, X_val, X_test, y_train, y_val, y_test = pickle.load(f)\n",
    "\n",
    "# EMOTIW2018\n",
    "with open(path+'emotiw_31_56.pkl','rb') as f:\n",
    "    X, y = pickle.load(f)\n",
    "\n",
    "# Averaged-data (DAISEE)\n",
    "def load_data(datafile):\n",
    "    df = pd.read_csv(datafile)\n",
    "    df = df.drop(df.columns[0], axis=1)\n",
    "    return df\n",
    "\n",
    "path_av = ('C:/Users/hasegawa-lab-pc/OneDrive - Japan Advanced Institute of Science and Technology/Documents/Dataset/DAiSEE/OpenFace_2.2.0_win_x64/processed/csv/labels/')\n",
    "df_train_av = load_data(path_av+'average_train.csv')\n",
    "df_val_av = load_data(path_av+'average_val.csv')\n",
    "df_test_av = load_data(path_av+'average_test.csv')\n",
    "df_all_av = pd.concat([df_train_av,df_val_av,df_test_av], axis=0, ignore_index=True)\n",
    "\n",
    "df_emotiw = load_data(path+'average_emotiw.csv')\n",
    "# df_emotiw.head()\n",
    "\n",
    "# SPLIT features and Label\n",
    "def split_label(df):\n",
    "    df = np.array(df)\n",
    "    Y = df[:,-1]\n",
    "    Y_en = LabelEncoder().fit_transform(Y) #encode label value as label variable\n",
    "    Y_cat = to_categorical(Y)\n",
    "    X = df[:,0:-1]    \n",
    "    return X, Y_en, Y_cat\n",
    "\n",
    "X_train_av, y_train_av, y_train_av_cat = split_label(df_train_av)\n",
    "X_val_av, y_val_av, y_val_av_cat = split_label(df_val_av)\n",
    "X_test_av, y_test_av, y_test_av_cat = split_label(df_test_av)\n",
    "X_all_av, Y_all_av, Y_all_av_cat = split_label(df_all_av)\n",
    "X_emotiw, y_emotiw, y_emotiw_cat = split_label(df_emotiw)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21e20c35",
   "metadata": {},
   "source": [
    "### PLOTS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bc8f0580",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_context('talk')\n",
    "sns.pairplot(df_test_av, hue='Engagement')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "96aee372",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8571 entries, 0 to 8570\n",
      "Columns: 330 entries,  gaze_0_x to Engagement\n",
      "dtypes: float64(330)\n",
      "memory usage: 21.6 MB\n"
     ]
    }
   ],
   "source": [
    "df_all_av.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "opposed-restoration",
   "metadata": {},
   "source": [
    "### Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "optimum-little",
   "metadata": {},
   "outputs": [],
   "source": [
    "# REGRESSION models\n",
    "model_1 = RandomForestRegressor(n_estimators=100, random_state=0)\n",
    "model_2 = XGBRegressor(random_state=0, learning_rate=0.05)\n",
    "model_3 = KNeighborsRegressor()\n",
    "model_4 = DecisionTreeRegressor()\n",
    "model_5 = SVR()\n",
    "model_6 = GaussianNB()\n",
    "\n",
    "# CLASSIFICATION models\n",
    "model_1c = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bigger-hybrid",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PRE-Processing\n",
    "preprocess = Pipeline([('scaled', StandardScaler()), ('pca', PCA(n_components=90, whiten=True))])\n",
    "preprocessKPCA = Pipeline([('pca', KernelPCA(n_components=90)),('scaled', StandardScaler())])\n",
    "\n",
    "# https://www.kaggle.com/rakesh2711/multiple-models-using-pipeline/notebook\n",
    "pipe = []\n",
    "pipe.append(('scaledRFG', (Pipeline([('scaled', StandardScaler()),('RGB', model_1)]))))\n",
    "pipe.append(('scaled_pca_RFG', (Pipeline([('preprocess', preprocess),('RGB', model_1)]))))\n",
    "pipe.append(('kpca_scaled_RFG', (Pipeline([('preprocessKPCA', preprocess),('RGB', model_1)]))))\n",
    "\n",
    "pipe.append(('scaledXGBR', (Pipeline([('scaled', StandardScaler()),('XGBR', model_2)]))))\n",
    "pipe.append(('scaled_pca_XGBR', (Pipeline([('preprocess', preprocess),('XGBR', model_2)]))))\n",
    "pipe.append(('kpca_scaled_XGBR', (Pipeline([('preprocessKPCA', preprocess),('XGBR', model_2)]))))\n",
    "\n",
    "pipe.append(('scaledKNN', (Pipeline([('scaled', StandardScaler()),('KNN', model_3)]))))\n",
    "pipe.append(('scaled_pca_KNN', (Pipeline([('preprocess', preprocess),('KNN', model_3)]))))\n",
    "pipe.append(('kpca_scaled_KNN', (Pipeline([('preprocessKPCA', preprocess),('KNN', model_3)]))))\n",
    "\n",
    "pipe.append(('scaledDT', (Pipeline([('scaled', StandardScaler()),('DT', model_4)]))))\n",
    "pipe.append(('scaled_pca_DT', (Pipeline([('preprocess', preprocess),('DT', model_4)]))))\n",
    "pipe.append(('kpca_scaled_DT', (Pipeline([('preprocessKPCA', preprocess),('DT', model_4)]))))\n",
    "\n",
    "pipe.append(('scaledSVR', (Pipeline([('scaled', StandardScaler()),('SVR', model_5)]))))\n",
    "pipe.append(('scaled_pca_SVR', (Pipeline([('preprocess', preprocess),('SVR', model_5)]))))\n",
    "pipe.append(('kpca_scaled_SVR', (Pipeline([('preprocessKPCA', preprocess),('SVR', model_5)]))))\n",
    "\n",
    "pipe.append(('scaledGNB', (Pipeline([('scaled', StandardScaler()),('GNB', model_6)]))))\n",
    "pipe.append(('scaled_pca_GNB', (Pipeline([('preprocess', preprocess),('GNB', model_6)]))))\n",
    "pipe.append(('kpca_scaled_GNB', (Pipeline([('preprocessKPCA', preprocess),('GNB', model_6)]))))\n",
    "# # pipe.append(('scaledLR', (Pipeline([('scaled', StandardScaler()), ('LR', model_1c)]))))\n",
    "# pipe.append(('scaled_pca_LR', (Pipeline([('preprocess', preprocess),('LR', model_1c)]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "associate-davis",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_kf(X,Y):\n",
    "    model_name = []\n",
    "    results = []\n",
    "    # results_acc = []\n",
    "\n",
    "    for pipes, model in pipe:\n",
    "        kf = KFold(n_splits=5)\n",
    "        cv_result = -1 * cross_val_score(model, X, Y, cv=kf, scoring='neg_mean_squared_error')\n",
    "        # cv_result = cross_val_score(model, X_all_av, Y_all_av, cv=kf, scoring='accuracy')\n",
    "\n",
    "        results.append(cv_result)\n",
    "        model_name.append(pipes)\n",
    "        msg = \"%s: %f: (%f)\" % (model_name, cv_result.mean(), cv_result.std())\n",
    "        print(msg)  \n",
    "\n",
    "    # PLOT Algorithm comparison\n",
    "    fig = plt.figure(figsize=(15,5))\n",
    "    fig.suptitle('Regression Algorithm Comparison (5-Fold CrossValidation)')\n",
    "    ax = fig.add_subplot(111)\n",
    "    plt.boxplot(results)\n",
    "    plt.xlabel('Model')\n",
    "    plt.ylabel('Mean Squared Error (MSE)')\n",
    "    ax.set_xticklabels(model_name)\n",
    "    plt.xticks(rotation=70)\n",
    "    plt.show()\n",
    "\n",
    "    return model_name, results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd97ce18",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name, results = train_kf(X_all_av,Y_all_av)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c637a5fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "emotiw_model_name, emotiw_results = train_kf(X_emotiw, y_emotiw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pacific-flush",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "dc86f5e1d763e51324beefa3721016490e22711f0b9054847e29143218b2ad33"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
